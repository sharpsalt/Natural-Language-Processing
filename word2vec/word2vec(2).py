# -*- coding: utf-8 -*-
"""word2vec.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/10-yfVQlJKOUCnQXFACAW4OU_SbiufQF_
"""

# Commented out IPython magic to ensure Python compatibility.
# %pip install gensim

import gensim

from gensim.models import Word2Vec,KeyedVectors

#This two libraries are very important as here we are taking google pretrained model

## References:  goto stackoverflow

import gensim.downloader as api
wv=api.load('word2vec-google-news-300')
vec_king=wv['king']

vec_king

vec_king.shape

wv['cricket']

wv.most_similar('cricket')

wv.most_similar('happy')

#here the distance is calculated using cosine similarity
wv.similarity("hockey","sports")

vec=wv['king']-wv['man']+wv['woman']
wv.most_similar([vec])

#Obviously king 1st pe hi rahega but most similar words after king is queen which is correct
#try to use it like it is very amamzing bro literally very amazing











